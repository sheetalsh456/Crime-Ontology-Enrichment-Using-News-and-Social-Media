{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import re\n",
    "from nltk import *\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key = 'BzZbuP9MoZKiJlRGWLt43L529'\n",
    "consumer_secret = 'UvjqFGMA9RyzIhYLhEqRTTPFWksG6r8eJjVQxbAenbSJNuiie3'\n",
    "access_token = '1673676428-LHmfijSx0QvqT3vPz7hTWjATZDbCBdR4TkrtqJ9'\n",
    "access_token_secret = 'UetYT7QN0cPOtmGOpbEilYIESf6haIx47b9BaUl6OKnEP'\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_continuous_chunks(text):\n",
    "    chunked = ne_chunk(pos_tag(word_tokenize(text)))\n",
    "    prev = None\n",
    "    continuous_chunk = []\n",
    "    current_chunk = []\n",
    "    for i in chunked:\n",
    "            if type(i) == Tree:\n",
    "                current_chunk.append(i.label()[:3] + \"-\")\n",
    "                current_chunk.append(\" \".join([token for token, pos in i.leaves()]))\n",
    "            elif current_chunk:\n",
    "                named_entity = \" \".join(current_chunk)\n",
    "                if named_entity not in continuous_chunk:\n",
    "                    continuous_chunk.append(named_entity)\n",
    "                    current_chunk = []\n",
    "            else:\n",
    "                continue\n",
    "    return continuous_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relation_tuples(sentences, image):\n",
    "    relation_tuples = []\n",
    "    for sentence in sentences:\n",
    "        rel_tuple_single = []\n",
    "        rel_tuple_single = get_continuous_chunks(sentence)\n",
    "        #print(rel_tuple_single)\n",
    "\n",
    "        if len(rel_tuple_single):\n",
    "            tokens = word_tokenize(sentence)\n",
    "            tagged = pos_tag(tokens)\n",
    "\n",
    "        #extract named entities\n",
    "        entities = chunk.ne_chunk(tagged)\n",
    "        #print entities\n",
    "        for entity in entities:\n",
    "\n",
    "            if len(entity)>1 and (entity[1] == 'VB' or entity[1] == 'VBD' or entity[1] == 'VBN' or entity[1] == 'VM'):\n",
    "                if entity[0] not in stopwords.words('english'):\n",
    "                    rel_tuple_single.append('REL-'+entity[0])\n",
    "        rel_tuple_single.append('IMG-'+image)\n",
    "\n",
    "        #print entity\n",
    "        if len(rel_tuple_single):\n",
    "            relation_tuples.append(rel_tuple_single)\n",
    "\n",
    "    with open(\"input.txt\", \"a\") as myfile:\n",
    "        myfile.write(str(relation_tuples)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = ['timesofindia', 'WeirdCrimeFacts', 'CyberCrimeNEWS', 'DNewsCrimeTeam', 'MadisonCrime', 'IowaMurderNews']\n",
    "\n",
    "for page in pages:\n",
    "    posts = api.user_timeline(screen_name=page, count = 40)\n",
    "    for post in posts:\n",
    "        if 'media' in post.entities:\n",
    "            text = re.sub(r\"http\\S+\", \"\", post.text)\n",
    "            if text:\n",
    "                try:\n",
    "                    get_relation_tuples(sent_tokenize(text), post.entities['media'][0]['media_url_https'])\n",
    "                except:\n",
    "                    i = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
